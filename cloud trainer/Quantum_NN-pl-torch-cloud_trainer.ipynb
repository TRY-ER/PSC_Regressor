{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import joblib\nimport random\nimport pandas as pd\nimport os\nimport optuna \nimport torch \nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset,DataLoader\nfrom torchmetrics import R2Score\nimport numpy as np\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-10T11:35:19.519368Z","iopub.execute_input":"2023-01-10T11:35:19.519726Z","iopub.status.idle":"2023-01-10T11:35:19.526615Z","shell.execute_reply.started":"2023-01-10T11:35:19.519695Z","shell.execute_reply":"2023-01-10T11:35:19.525614Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"! pip install pennylane==0.27.0","metadata":{"execution":{"iopub.status.busy":"2023-01-10T11:35:20.644455Z","iopub.execute_input":"2023-01-10T11:35:20.644853Z","iopub.status.idle":"2023-01-10T11:35:34.557016Z","shell.execute_reply.started":"2023-01-10T11:35:20.644818Z","shell.execute_reply":"2023-01-10T11:35:34.555811Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Collecting pennylane==0.27.0\n  Downloading PennyLane-0.27.0-py3-none-any.whl (1.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n\u001b[?25hCollecting autoray>=0.3.1\n  Downloading autoray-0.5.3-py3-none-any.whl (39 kB)\nRequirement already satisfied: cachetools in /opt/conda/lib/python3.7/site-packages (from pennylane==0.27.0) (4.2.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from pennylane==0.27.0) (1.7.3)\nCollecting pennylane-lightning>=0.27\n  Downloading PennyLane_Lightning-0.28.0-py3-none-any.whl (227 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.2/227.2 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: appdirs in /opt/conda/lib/python3.7/site-packages (from pennylane==0.27.0) (1.4.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from pennylane==0.27.0) (2.28.1)\nRequirement already satisfied: toml in /opt/conda/lib/python3.7/site-packages (from pennylane==0.27.0) (0.10.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.7/site-packages (from pennylane==0.27.0) (2.5)\nCollecting autograd\n  Downloading autograd-1.5-py3-none-any.whl (48 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting retworkx\n  Downloading retworkx-0.12.1-py3-none-any.whl (10 kB)\nCollecting semantic-version>=2.7\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from pennylane==0.27.0) (1.21.6)\nRequirement already satisfied: ninja in /opt/conda/lib/python3.7/site-packages (from pennylane-lightning>=0.27->pennylane==0.27.0) (1.11.1)\nRequirement already satisfied: future>=0.15.2 in /opt/conda/lib/python3.7/site-packages (from autograd->pennylane==0.27.0) (0.18.2)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx->pennylane==0.27.0) (5.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->pennylane==0.27.0) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->pennylane==0.27.0) (1.26.13)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->pennylane==0.27.0) (2.1.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->pennylane==0.27.0) (2022.12.7)\nCollecting rustworkx==0.12.1\n  Downloading rustworkx-0.12.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: semantic-version, rustworkx, autoray, autograd, retworkx, pennylane-lightning, pennylane\nSuccessfully installed autograd-1.5 autoray-0.5.3 pennylane-0.27.0 pennylane-lightning-0.28.0 retworkx-0.12.1 rustworkx-0.12.1 semantic-version-2.10.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import pennylane as qml","metadata":{"execution":{"iopub.status.busy":"2023-01-10T11:35:38.769366Z","iopub.execute_input":"2023-01-10T11:35:38.769779Z","iopub.status.idle":"2023-01-10T11:35:39.402948Z","shell.execute_reply.started":"2023-01-10T11:35:38.769719Z","shell.execute_reply":"2023-01-10T11:35:39.401895Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available else \"cpu\"\n\nn_qubits = 2\ndev = qml.device(\"default.qubit\", wires=n_qubits)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T11:35:43.929266Z","iopub.execute_input":"2023-01-10T11:35:43.929958Z","iopub.status.idle":"2023-01-10T11:35:44.405689Z","shell.execute_reply.started":"2023-01-10T11:35:43.929920Z","shell.execute_reply":"2023-01-10T11:35:44.404735Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#configuring the quantum node \n@qml.qnode(dev,interface=\"torch\")\ndef quantum_circuit(params,x):\n    # Encoding the input data into quantum states\n    qml.RX(x[0], wires=0)\n    qml.RY(x[1], wires=1)\n    qml.CNOT(wires= [0,1])\n    return qml.expval(qml.PauliZ(0)),qml.expval(qml.PauliZ(1)) ","metadata":{"execution":{"iopub.status.busy":"2023-01-10T11:35:47.789344Z","iopub.execute_input":"2023-01-10T11:35:47.789786Z","iopub.status.idle":"2023-01-10T11:35:47.800479Z","shell.execute_reply.started":"2023-01-10T11:35:47.789718Z","shell.execute_reply":"2023-01-10T11:35:47.799417Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#Defining the NN\nclass NN(torch.nn.Module):\n    def __init__(self,in_feature):\n        super().__init__()\n        self.in_feature = in_feature\n        self.hid1 = torch.nn.Linear(in_feature, 128)\n        self.dropout = nn.Dropout(0.25)\n#         self.batchnorm1 = nn.BatchNorm1d(128)\n        self.hid2 = torch.nn.Linear(128,64)\n        self.hid3 = torch.nn.Linear(64,32)\n        self.output = torch.nn.Linear(32,1)\n        \n        torch.nn.init.xavier_uniform_(self.hid1.weight)\n        torch.nn.init.zeros_(self.hid1.bias)\n        torch.nn.init.xavier_uniform_(self.hid2.weight)\n        torch.nn.init.zeros_(self.hid2.bias)\n        torch.nn.init.xavier_uniform_(self.hid3.weight)\n        torch.nn.init.zeros_(self.hid3.bias)\n        torch.nn.init.xavier_uniform_(self.output.weight)\n        torch.nn.init.zeros_(self.output.bias)\n    \n    def forward(self,x):\n        z = torch.relu(self.hid1(x))\n#         z = self.batchnorm1(z)\n        z = self.dropout(z)\n        z = torch.relu(self.hid2(z))\n        z = self.dropout(z)\n        z = torch.relu(self.hid3(z))\n        z = self.output(z)\n        return z","metadata":{"execution":{"iopub.status.busy":"2023-01-10T11:38:18.415826Z","iopub.execute_input":"2023-01-10T11:38:18.416533Z","iopub.status.idle":"2023-01-10T11:38:18.426762Z","shell.execute_reply.started":"2023-01-10T11:38:18.416494Z","shell.execute_reply":"2023-01-10T11:38:18.425784Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Defining the QNN\nclass QuantNN(torch.nn.Module):\n    def __init__(self,quantum_circuit, class_NN):\n        super().__init__()\n        self.quantum_circuit = quantum_circuit\n        self.class_nn = class_NN\n        \n    def forward(self,x):\n        quant_out = self.quantum_circuit(x)\n        class_in = torch.tensor(quant_out,device=device)\n        class_out = self.class_nn(class_in.float())\n        # Debugging\n        print(f\"quant_in: {x.shape}\")\n        print(f\"quant_out: {quant_out.shape}\")\n        print(f\"class_in: {class_in.shape}\")\n        print(f\"class_out: {class_out.shape}\")\n        return class_out\n","metadata":{"execution":{"iopub.status.busy":"2023-01-10T11:38:20.419271Z","iopub.execute_input":"2023-01-10T11:38:20.419695Z","iopub.status.idle":"2023-01-10T11:38:20.424291Z","shell.execute_reply.started":"2023-01-10T11:38:20.419660Z","shell.execute_reply":"2023-01-10T11:38:20.423311Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"#preparing the dataset class for the input\nclass CustDataset(Dataset):\n    \n    def __init__(self,df):\n        self.labels = df[TAR_COL].to_numpy(dtype=np.float64)\n        self.features = df.drop([TAR_COL],axis=1).to_numpy(dtype=np.float64)\n        \n    def classes(self):\n        return self.labels\n    def __len__(self):\n        return len(self.labels)\n    def get_batch_labels(self,idx):\n        return np.array(self.labels[idx])\n    \n    def get_batch_features(self,idx):\n        return np.array(self.features[idx])\n    \n    def __getitem__(self,idx):\n        batch_features = self.get_batch_features(idx)\n        batch_y = self.get_batch_labels(idx)\n        \n        return batch_features, batch_y   ","metadata":{"execution":{"iopub.status.busy":"2023-01-10T11:38:20.663839Z","iopub.execute_input":"2023-01-10T11:38:20.664448Z","iopub.status.idle":"2023-01-10T11:38:20.672427Z","shell.execute_reply.started":"2023-01-10T11:38:20.664416Z","shell.execute_reply":"2023-01-10T11:38:20.671341Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"#Redirecting the QNN\n\ndef build_model(in_features):\n    NeuN = NN(in_features)\n    QuantNeuN = qml.qnn.TorchLayer(quantum_circuit,NeuN, device)\n    return QuantNeuN","metadata":{"execution":{"iopub.status.busy":"2023-01-10T11:38:44.839660Z","iopub.execute_input":"2023-01-10T11:38:44.840061Z","iopub.status.idle":"2023-01-10T11:38:44.845177Z","shell.execute_reply.started":"2023-01-10T11:38:44.840027Z","shell.execute_reply":"2023-01-10T11:38:44.844114Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"FOLD_DICT = joblib.load(\"../input/perov-fold-data/fold_data_export.z\")\nUSE_DF = pd.read_csv(\"../input/perov-scaled-data/scaled_trainable.csv\")\nTAR_COL = \"JV_default_PCE_numeric\"\nEPOCHS = 3\nK_FOLD = 2\nIN_FEATURES = 103 ","metadata":{"execution":{"iopub.status.busy":"2023-01-10T11:38:45.808976Z","iopub.execute_input":"2023-01-10T11:38:45.809346Z","iopub.status.idle":"2023-01-10T11:38:46.811292Z","shell.execute_reply.started":"2023-01-10T11:38:45.809314Z","shell.execute_reply":"2023-01-10T11:38:46.810240Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def train_eval(params, model,fold,trial):\n    \n    #loading data \n    train_index = FOLD_DICT[fold][\"train\"]\n    test_index = FOLD_DICT[fold][\"test\"]\n    train = CustDataset(USE_DF.iloc[train_index,:])\n    val = CustDataset(USE_DF.iloc[test_index,:])\n    train_loader = DataLoader(train,batch_size = 32, shuffle=False)\n    val_loader = DataLoader(val,batch_size= 32, shuffle=False)\n    \n    cuda_bool = torch.cuda.is_available()\n    device = torch.device(\"cuda\" if cuda_bool else \"cpu\")\n    \n    criterion = nn.MSELoss()\n    optimizer = getattr(optim, params[\"optimizer\"])(model.parameters(),lr=params[\"learning_rate\"])\n    \n    #creating custom early stopping\n    patience = 2\n    best_val_loss = float(\"inf\")\n    counter = 0\n    \n    if cuda_bool:\n        model = model.cuda()\n        criterion = criterion.cuda()\n        \n    \n    \n    for epoch_num in range(EPOCHS):\n        \n        loss_list = []\n        #training loop \n        for train_x, train_y in train_loader:\n            \n            train_y = train_y.to(device)\n            train_y = train_y.reshape((train_y.shape[0],1))\n            train_x = train_x.to(device)\n            \n            output = model(train_x.float())\n            \n            batch_loss = criterion(output, train_y.float())\n            \n            optimizer.zero_grad()\n            \n            model.zero_grad()\n            batch_loss.backward()\n            optimizer.step()       \n        \n        model.eval()\n        with torch.no_grad():\n            \n            loss = 0.0\n            #validation loop \n            for val_x,val_y in val_loader:\n                \n                val_x = val_x.to(device)\n                val_y = val_y.reshape((val_y.shape[0],1))\n                val_y = val_y.to(device)\n                \n                output = model(val_x.float())\n                \n                batch_loss = criterion(output, val_y.float())\n                loss += batch_loss.item()\n                loss_list.append(batch_loss.item())\n            print(f\"Validating:[{epoch_num+1}/{EPOCHS}] LOSS: {batch_loss.item()}]\")\n        if loss < best_val_loss:\n            best_val_loss = loss\n            counter = 0\n        else: \n            counter += 1\n            if counter >= patience: \n                print(f\"[==] Early Stopping at {loss}\")\n                break\n        \n    main_loss = np.mean(loss_list)\n    return main_loss","metadata":{"execution":{"iopub.status.busy":"2023-01-10T11:38:46.814167Z","iopub.execute_input":"2023-01-10T11:38:46.814843Z","iopub.status.idle":"2023-01-10T11:38:46.828946Z","shell.execute_reply.started":"2023-01-10T11:38:46.814801Z","shell.execute_reply":"2023-01-10T11:38:46.827816Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"#defing optuna objective function\ndef objective(trial):\n    params = {\n        \"learning_rate\": trial.suggest_float(\"learning_rate\",1e-5, 1e-1),\n        \"optimizer\" : trial.suggest_categorical(\"optimizer\",[\"Adam\", \"RMSprop\", \"SGD\"])\n    }\n    \n    fold = TRIAL_FOLD\n    model = build_model(IN_FEATURES)\n    main_loss = train_eval(params, model,fold, trial)\n    \n    return main_loss ","metadata":{"execution":{"iopub.status.busy":"2023-01-10T11:38:49.158011Z","iopub.execute_input":"2023-01-10T11:38:49.158364Z","iopub.status.idle":"2023-01-10T11:38:49.164205Z","shell.execute_reply.started":"2023-01-10T11:38:49.158332Z","shell.execute_reply":"2023-01-10T11:38:49.163105Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Definging best hyper parameteres\nNUM_TRIALS = 10\nTRIAL_FOLD = random.choice([x for x in range(K_FOLD)])\nstudy = optuna.create_study(direction=\"minimize\",\n                            sampler=optuna.samplers.TPESampler(),\n                            pruner=optuna.pruners.MedianPruner())\nstudy.optimize(objective, n_trials=NUM_TRIALS)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T11:38:49.633309Z","iopub.execute_input":"2023-01-10T11:38:49.633971Z","iopub.status.idle":"2023-01-10T11:38:49.691736Z","shell.execute_reply.started":"2023-01-10T11:38:49.633934Z","shell.execute_reply":"2023-01-10T11:38:49.690143Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"\u001b[32m[I 2023-01-10 11:38:49,636]\u001b[0m A new study created in memory with name: no-name-8009cdc2-9096-4d88-9af1-825c78873bb6\u001b[0m\n\u001b[33m[W 2023-01-10 11:38:49,642]\u001b[0m Trial 0 failed because of the following error: AttributeError(\"'NN' object has no attribute 'items'\")\u001b[0m\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n    value_or_values = func(trial)\n  File \"/tmp/ipykernel_23/1312651667.py\", line 9, in objective\n    model = build_model(IN_FEATURES)\n  File \"/tmp/ipykernel_23/1557917407.py\", line 5, in build_model\n    QuantNeuN = qml.qnn.TorchLayer(quantum_circuit,NeuN, device)\n  File \"/opt/conda/lib/python3.7/site-packages/pennylane/qnn/torch.py\", line 257, in __init__\n    for weight, size in weight_shapes.items()\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1186, in __getattr__\n    type(self).__name__, name))\nAttributeError: 'NN' object has no attribute 'items'\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/1991262222.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                             \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                             pruner=optuna.pruners.MedianPruner())\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_TRIALS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         )\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     ):\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/1312651667.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTRIAL_FOLD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIN_FEATURES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mmain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/1557917407.py\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(in_features)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mNeuN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mQuantNeuN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTorchLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquantum_circuit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNeuN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mQuantNeuN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pennylane/qnn/torch.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, qnode, weight_shapes, init_method)\u001b[0m\n\u001b[1;32m    255\u001b[0m         weight_shapes = {\n\u001b[1;32m    256\u001b[0m             \u001b[0mweight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweight_shapes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         }\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1186\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NN' object has no attribute 'items'"],"ename":"AttributeError","evalue":"'NN' object has no attribute 'items'","output_type":"error"}]},{"cell_type":"code","source":"#CAPTURING BEST HYPERPARAMETERS\nbest_param = study.best_params\nbest_param","metadata":{"execution":{"iopub.status.busy":"2023-01-10T09:45:23.477621Z","iopub.execute_input":"2023-01-10T09:45:23.477996Z","iopub.status.idle":"2023-01-10T09:45:23.484932Z","shell.execute_reply.started":"2023-01-10T09:45:23.477963Z","shell.execute_reply":"2023-01-10T09:45:23.483977Z"},"trusted":true},"execution_count":84,"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"{'learning_rate': 0.09392347823813403, 'optimizer': 'Adam'}"},"metadata":{}}]},{"cell_type":"code","source":"#Creating train function for all folds\ndef main_train(best_param, model,fold):\n    \n    #loading data \n    train_index = FOLD_DICT[fold][\"train\"]\n    test_index = FOLD_DICT[fold][\"test\"]\n    train = CustDataset(USE_DF.iloc[train_index,:])\n    val = CustDataset(USE_DF.iloc[test_index,:])\n    \n    cuda_bool = torch.cuda.is_available()\n    device = torch.device(\"cuda\" if cuda_bool else \"cpu\")\n    \n    train_x = torch.tensor(train.features, device=device)\n    train_y = torch.tensor(train.labels, device=device)\n    val_x = torch.tensor(val.features, device=device)\n    val_y = torch.tensor(val.labels , device=device)\n    \n    criterion = nn.MSELoss()\n    optimizer = getattr(optim,best_param[\"optimizer\"])(model.parameters(),lr=best_param[\"learning_rate\"])\n    \n    \n    #creating custom early stopping\n    patience = 3\n    best_val_loss = float(\"inf\")\n    counter = 0 \n    \n    \n    if cuda_bool:\n        model = model.cuda()\n        criterion = criterion.cuda()\n        \n    \n    \n    for epoch_num in range(EPOCHS):\n        \n        mean_sq_list = []\n        r_mean_sq_list = []\n        mean_abs_list = []\n        r2_list = []\n        \n            \n        optimizer.zero_grad()\n\n        train_y = train_y.to(device)\n        train_y = train_y.reshape((train_y.shape[0],1))\n        train_x = train_x.to(device)\n\n#             print(train_x.shape)\n        print(train_x.shape)\n        output = model(train_x.float())\n        print(output.shape)\n#             print(output.shape)\n\n        batch_loss = criterion(output, train_y.float())\n        print(batch_loss)\n\n        model.zero_grad()\n        batch_loss.backward()\n        optimizer.step()\n\n\n          \n        \n        model.eval()\n        with torch.no_grad():\n            \n            #validation loop \n            loss = 0.0\n            for val_x,val_y in val_loader:\n                \n                val_x = val_x.to(device)\n                val_y = val_y.reshape((val_y.shape[0],1))\n                val_y = val_y.to(device)\n                \n                print(val_x.shape)\n                output = model(val.float())\n#                     output_vals.append(output)\n                print(len(output_vals))\n                print(output.shape)\n                batch_loss = criterion(output, val_y.float())\n                loss += batch_loss.item()\n                mean_abs_error = nn.L1Loss()(output, val_y)\n                r_mean_sq_error = torch.sqrt(batch_loss)\n                r2_score = R2Score().to(device)(output.reshape((output.shape[0],1)), val_y)\n                mean_sq_list.append(batch_loss.item())\n                mean_abs_list.append(mean_abs_error.item())\n                r2_list.append(r2_score.item())\n                r_mean_sq_list.append(r_mean_sq_error.item())\n            print(f\"Validating:[{epoch_num+1}/{EPOCHS}] LOSS: {batch_loss.item()}]\")\n        if loss < best_val_loss:\n            best_val_loss = loss\n            counter = 0\n        else: \n            counter += 1\n            if counter >= patience: \n                print(f\"[==] Early Stopping at {loss}\")\n                break\n        \n    sq_mean_loss = np.mean(mean_sq_list)\n    r_sq_mean_loss = np.mean(r_mean_sq_list)\n    abs_mean_loss = np.mean(mean_abs_list)\n    r2_mean_loss = np.mean(r2_list)\n    \n    error = {\"mse_error\" : sq_mean_loss ,\n    \"mae_error\" : abs_mean_loss,\n    \"rmse_error\" : r_sq_mean_loss,\n    \"r2_score\" :  r2_mean_loss}\n    return error,model","metadata":{"execution":{"iopub.status.busy":"2023-01-10T10:24:18.468538Z","iopub.execute_input":"2023-01-10T10:24:18.468882Z","iopub.status.idle":"2023-01-10T10:24:18.480899Z","shell.execute_reply.started":"2023-01-10T10:24:18.468853Z","shell.execute_reply":"2023-01-10T10:24:18.479946Z"},"trusted":true},"execution_count":164,"outputs":[]},{"cell_type":"code","source":"def save_cv_model(i,model_name,model,optim,losses,output_path=\"./\"):\n\n    ''' This function saves cross validation model in the corresponding directory ( if the path does not exist it creates the path for it'''\n\n\n    if os.path.exists(os.path.join(output_path,f\"{i}_{model_name}_{optim}\")):\n        torch.save(model, os.path.join(output_path,f\"{i}_{model_name}_{optim}/{i}_model.z\"))\n        with open(os.path.join(output_path,f\"{i}_{model_name}_{optim}/losses_{fold}.txt\"),\"w+\") as file:file.write(f\" mse_loss :: {str(losses)}\")\n    else:\n        os.mkdir(os.path.join(output_path,f\"{i}_{model_name}_{optim}\"))\n        torch.save(model, os.path.join(output_path,f\"{i}_{model_name}_{optim}/{i}_model.z\"))\n        with open(os.path.join(output_path,f\"{i}_{model_name}_{optim}/losses_{fold}.txt\"),\"w+\") as file:file.write(f\" mse_loss :: {str(losses)}\")","metadata":{"execution":{"iopub.status.busy":"2023-01-10T10:24:19.186135Z","iopub.execute_input":"2023-01-10T10:24:19.186487Z","iopub.status.idle":"2023-01-10T10:24:19.194495Z","shell.execute_reply.started":"2023-01-10T10:24:19.186457Z","shell.execute_reply":"2023-01-10T10:24:19.193368Z"},"trusted":true},"execution_count":165,"outputs":[]},{"cell_type":"code","source":"model_name = \"QNN\"\noptim_name = best_param[\"optimizer\"]\nfor fold in [x for x in range(K_FOLD)]:\n    dum_model = build_model(IN_FEATURES)\n    print(f\"Training for fold [{fold+1}/{K_FOLD}] started \")\n    error,model = main_train(best_param,dum_model,fold)\n    print(f\"Saving data for fold [{fold+1}/{K_FOLD}]\")\n    save_cv_model(fold,model_name,model,optim_name,error,output_path=\"./\")","metadata":{"execution":{"iopub.status.busy":"2023-01-10T10:24:19.761479Z","iopub.execute_input":"2023-01-10T10:24:19.761829Z","iopub.status.idle":"2023-01-10T10:24:19.870355Z","shell.execute_reply.started":"2023-01-10T10:24:19.761799Z","shell.execute_reply":"2023-01-10T10:24:19.868990Z"},"trusted":true},"execution_count":166,"outputs":[{"name":"stdout","text":"Training for fold [1/2] started \ntorch.Size([44479, 103])\nquant_in: torch.Size([44479, 103])\nquant_out: torch.Size([103])\nclass_in: torch.Size([103])\nclass_out: torch.Size([1])\ntorch.Size([1])\ntensor(489.7986, device='cuda:0', grad_fn=<MseLossBackward0>)\ntorch.Size([44479, 103])\nquant_in: torch.Size([44479, 103])\nquant_out: torch.Size([103])\nclass_in: torch.Size([103])\nclass_out: torch.Size([1])\ntorch.Size([1])\ntensor(15927.7061, device='cuda:0', grad_fn=<MseLossBackward0>)\ntorch.Size([44479, 103])\nquant_in: torch.Size([44479, 103])\nquant_out: torch.Size([103])\nclass_in: torch.Size([103])\nclass_out: torch.Size([1])\ntorch.Size([1])\ntensor(7536.1436, device='cuda:0', grad_fn=<MseLossBackward0>)\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  # Remove the CWD from sys.path while we load stuff.\n/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([44479, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n  return F.mse_loss(input, target, reduction=self.reduction)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/89892206.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdum_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIN_FEATURES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training for fold [{fold+1}/{K_FOLD}] started \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_param\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdum_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Saving data for fold [{fold+1}/{K_FOLD}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msave_cv_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptim_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"],"ename":"TypeError","evalue":"cannot unpack non-iterable NoneType object","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}