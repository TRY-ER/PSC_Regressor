{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install -U kaleido \n! pip install joblib optuna torch numpy ","metadata":{"execution":{"iopub.status.busy":"2023-01-10T09:41:48.924162Z","iopub.execute_input":"2023-01-10T09:41:48.924836Z","iopub.status.idle":"2023-01-10T09:41:52.073156Z","shell.execute_reply.started":"2023-01-10T09:41:48.924689Z","shell.execute_reply":"2023-01-10T09:41:52.072116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import joblib\nimport random\nimport pandas as pd\nimport os\nimport optuna \nimport torch \nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset,DataLoader\nfrom torchmetrics import R2Score\nimport numpy as np\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FOLD_DICT = joblib.load(\"../input/perov-fold-data/fold_data_export.z\")\nUSE_DF = pd.read_csv(\"../input/perov-scaled-data/scaled_trainable.csv\")\nTAR_COL = \"JV_default_PCE_numeric\"\nEPOCHS = 700\nK_FOLD = 20\nIN_FEATURES = 103 ","metadata":{"execution":{"iopub.status.busy":"2023-01-10T09:41:52.075123Z","iopub.execute_input":"2023-01-10T09:41:52.075477Z","iopub.status.idle":"2023-01-10T09:41:54.710079Z","shell.execute_reply.started":"2023-01-10T09:41:52.075433Z","shell.execute_reply":"2023-01-10T09:41:54.709233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#preparing the dataset class for the input\nclass CustDataset(Dataset):\n    \n    def __init__(self,df):\n        self.labels = df[TAR_COL].to_numpy(dtype=np.float64)\n        self.features = df.drop([TAR_COL],axis=1).to_numpy(dtype=np.float64)\n        \n    def classes(self):\n        return self.labels\n    def __len__(self):\n        return len(self.labels)\n    def get_batch_labels(self,idx):\n        return np.array(self.labels[idx])\n    \n    def get_batch_features(self,idx):\n        return np.array(self.features[idx])\n    \n    def __getitem__(self,idx):\n        batch_features = self.get_batch_features(idx)\n        batch_y = self.get_batch_labels(idx)\n        \n        return batch_features, batch_y   \n","metadata":{"execution":{"iopub.status.busy":"2023-01-10T09:41:54.711488Z","iopub.execute_input":"2023-01-10T09:41:54.711819Z","iopub.status.idle":"2023-01-10T09:41:54.719960Z","shell.execute_reply.started":"2023-01-10T09:41:54.711779Z","shell.execute_reply":"2023-01-10T09:41:54.718804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Building the MLP\nclass MLP(torch.nn.Module):\n    def __init__(self,in_feature):\n        super(MLP,self).__init__()\n        self.in_feature = in_feature\n        self.hid1 = torch.nn.Linear(in_feature, 128)\n        self.dropout = nn.Dropout(0.25)\n        self.batchnorm1 = nn.BatchNorm1d(128)\n        self.hid2 = torch.nn.Linear(128,64)\n        self.hid3 = torch.nn.Linear(64,32)\n        self.output = torch.nn.Linear(32,1)\n        \n        torch.nn.init.xavier_uniform_(self.hid1.weight)\n        torch.nn.init.zeros_(self.hid1.bias)\n        torch.nn.init.xavier_uniform_(self.hid2.weight)\n        torch.nn.init.zeros_(self.hid2.bias)\n        torch.nn.init.xavier_uniform_(self.hid3.weight)\n        torch.nn.init.zeros_(self.hid3.bias)\n        torch.nn.init.xavier_uniform_(self.output.weight)\n        torch.nn.init.zeros_(self.output.bias)\n    \n    def forward(self,x):\n        z = torch.relu(self.hid1(x))\n        z = self.batchnorm1(z)\n#         z = self.dropout(z)\n        z = torch.relu(self.hid2(z))\n#         z = self.dropout(z)\n        z = torch.relu(self.hid3(z))\n        z = self.output(z)\n        return z","metadata":{"execution":{"iopub.status.busy":"2023-01-10T09:48:09.215511Z","iopub.execute_input":"2023-01-10T09:48:09.216568Z","iopub.status.idle":"2023-01-10T09:48:09.230762Z","shell.execute_reply.started":"2023-01-10T09:48:09.216513Z","shell.execute_reply":"2023-01-10T09:48:09.229664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Redirecting the MLP \n\ndef build_model(in_features):\n    return MLP(in_features)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-01-10T09:41:54.735737Z","iopub.execute_input":"2023-01-10T09:41:54.736228Z","iopub.status.idle":"2023-01-10T09:41:54.748669Z","shell.execute_reply.started":"2023-01-10T09:41:54.736179Z","shell.execute_reply":"2023-01-10T09:41:54.747497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_optuna_plots(study,dirname):\n    optim_hist = optuna.visualization.plot_optimization_history(study)\n    intermediate = optuna.visualization.plot_intermediate_values(study)\n    parallel = optuna.visualization.plot_parallel_coordinate(study)\n    plot_slice = optuna.visualization.plot_slice(study)\n    name_lists = [\"optim_hist\",\"intermediate\",\"parallel\", \"plot_slice\"]\n    plot_lists = [optim_hist,intermediate,parallel, plot_slice]\n    for name,plot in zip(name_lists,plot_lists):\n        if os.path.exists(f\"./{dirname}\"):\n            print(\"getting into if block\")\n            plot.write_image(f\"./{dirname}/{name}.jpg\",width=2, height=2)\n        else:\n            print(\"getting into else block\")\n            os.mkdir(f\"./{dirname}\")\n            plot.write_image(f\"./{dirname}/{name}.jpg\",width=2, height=2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_eval(params, model,fold,trial):\n    \n    #loading data \n    train_index = FOLD_DICT[fold][\"train\"]\n    test_index = FOLD_DICT[fold][\"test\"]\n    train = CustDataset(USE_DF.iloc[train_index,:])\n    val = CustDataset(USE_DF.iloc[test_index,:])\n    train_loader = DataLoader(train,batch_size = 32, shuffle=False)\n    val_loader = DataLoader(val,batch_size= 32, shuffle=False)\n    \n    cuda_bool = torch.cuda.is_available()\n    device = torch.device(\"cuda\" if cuda_bool else \"cpu\")\n    \n    criterion = nn.MSELoss()\n    optimizer = getattr(optim, params[\"optimizer\"])(model.parameters(),lr=params[\"learning_rate\"])\n    \n    #creating custom early stopping\n    patience = 5\n    best_val_loss = float(\"inf\")\n    counter = 0\n    \n    if cuda_bool:\n        model = model.cuda()\n        criterion = criterion.cuda()\n        \n    \n    \n    for epoch_num in range(EPOCHS):\n        \n        loss_list = []\n        #training loop \n        for train_x, train_y in train_loader:\n            \n            train_y = train_y.to(device)\n            train_y = train_y.reshape((train_y.shape[0],1))\n            train_x = train_x.to(device)\n            \n            output = model(train_x.float())\n            \n            batch_loss = criterion(output, train_y.float())\n            \n            optimizer.zero_grad()\n            \n            model.zero_grad()\n            batch_loss.backward()\n            optimizer.step()\n\n\n          \n        \n        model.eval()\n        with torch.no_grad():\n            \n            loss = 0.0\n            #validation loop \n            for val_x,val_y in val_loader:\n                \n                val_x = val_x.to(device)\n                val_y = val_y.reshape((val_y.shape[0],1))\n                val_y = val_y.to(device)\n                \n                output = model(val_x.float())\n                \n                batch_loss = criterion(output, val_y.float())\n                loss += batch_loss.item()\n                loss_list.append(batch_loss.item())\n            print(f\"Validating:[{epoch_num+1}/{EPOCHS}] LOSS: {batch_loss.item()}]\")\n        if loss < best_val_loss:\n            best_val_loss = loss\n            counter = 0\n        else: \n            counter += 1\n            if counter >= patience: \n                print(f\"[==] Early Stopping at {loss}\")\n                break\n        \n    main_loss = np.mean(loss_list)\n    return main_loss","metadata":{"execution":{"iopub.status.busy":"2023-01-10T09:41:54.751483Z","iopub.execute_input":"2023-01-10T09:41:54.752041Z","iopub.status.idle":"2023-01-10T09:41:54.769379Z","shell.execute_reply.started":"2023-01-10T09:41:54.751975Z","shell.execute_reply":"2023-01-10T09:41:54.768259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#defing optuna objective function\ndef objective(trial):\n    params = {\n        \"learning_rate\": trial.suggest_float(\"learning_rate\",1e-5, 1e-1),\n        \"optimizer\" : trial.suggest_categorical(\"optimizer\",[\"Adam\", \"RMSprop\", \"SGD\"])\n    }\n    \n    fold = TRIAL_FOLD\n    model = build_model(IN_FEATURES)\n    main_loss = train_eval(params, model,fold, trial)\n    \n    return main_loss ","metadata":{"execution":{"iopub.status.busy":"2023-01-10T09:41:54.771356Z","iopub.execute_input":"2023-01-10T09:41:54.771648Z","iopub.status.idle":"2023-01-10T09:41:54.784639Z","shell.execute_reply.started":"2023-01-10T09:41:54.771617Z","shell.execute_reply":"2023-01-10T09:41:54.783521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Definging best hyper parameteres\nNUM_TRIALS = 30\nTRIAL_FOLD = random.choice([x for x in range(K_FOLD)])\nstudy = optuna.create_study(direction=\"minimize\",\n                            sampler=optuna.samplers.TPESampler(),\n                            pruner=optuna.pruners.MedianPruner())\nstudy.optimize(objective, n_trials=NUM_TRIALS)\nsave_optuna_plots(study,\"optuna_plots\")\n","metadata":{"execution":{"iopub.status.busy":"2023-01-10T09:41:54.786238Z","iopub.execute_input":"2023-01-10T09:41:54.787166Z","iopub.status.idle":"2023-01-10T09:42:46.524431Z","shell.execute_reply.started":"2023-01-10T09:41:54.787115Z","shell.execute_reply":"2023-01-10T09:42:46.523312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#CAPTURING BEST HYPERPARAMETERS\nbest_param = study.best_params\nbest_param","metadata":{"execution":{"iopub.status.busy":"2023-01-10T09:42:49.043954Z","iopub.execute_input":"2023-01-10T09:42:49.044341Z","iopub.status.idle":"2023-01-10T09:42:49.055810Z","shell.execute_reply.started":"2023-01-10T09:42:49.044299Z","shell.execute_reply":"2023-01-10T09:42:49.054890Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creating train function for all folds\ndef main_train(best_param, model,fold):\n    \n    #loading data \n    train_index = FOLD_DICT[fold][\"train\"]\n    test_index = FOLD_DICT[fold][\"test\"]\n    train = CustDataset(USE_DF.iloc[train_index,:])\n    val = CustDataset(USE_DF.iloc[test_index,:])\n    train_loader = DataLoader(train,batch_size = 32, shuffle=False)\n    val_loader = DataLoader(val,batch_size= 32, shuffle=False)\n    \n    cuda_bool = torch.cuda.is_available()\n    device = torch.device(\"cuda\" if cuda_bool else \"cpu\")\n    \n    criterion = nn.MSELoss()\n    optimizer = getattr(optim,best_param[\"optimizer\"])(model.parameters(),lr=best_param[\"learning_rate\"])\n    \n    \n    #creating custom early stopping\n    patience = 5\n    best_val_loss = float(\"inf\")\n    counter = 0 \n    \n    \n    if cuda_bool:\n        model = model.cuda()\n        criterion = criterion.cuda()\n        \n    \n    \n    for epoch_num in range(EPOCHS):\n        \n        mean_sq_list = []\n        r_mean_sq_list = []\n        mean_abs_list = []\n        r2_list = []\n        #training loop \n        for train_x, train_y in train_loader:\n            \n            train_y = train_y.to(device)\n            train_y = train_y.reshape((train_y.shape[0],1))\n            train_x = train_x.to(device)\n            \n            print(train_x.shape)\n            output = model(train_x.float())\n            print(output.shape)\n            batch_loss = criterion(output, train_y.float())\n            print(batch_loss)\n            optimizer.zero_grad()\n            \n            model.zero_grad()\n            batch_loss.backward()\n            optimizer.step()\n\n\n          \n        \n        model.eval()\n        with torch.no_grad():\n            \n            #validation loop \n            loss = 0.0\n            for val_x,val_y in val_loader:\n                \n                val_x = val_x.to(device)\n                val_y = val_y.reshape((val_y.shape[0],1))\n                val_y = val_y.to(device)\n                \n                output = model(val_x.float())\n                \n                batch_loss = criterion(output, val_y.float())\n                loss += batch_loss.item()\n                mean_abs_error = nn.L1Loss()(output, val_y)\n                r_mean_sq_error = torch.sqrt(batch_loss)\n                r2_score = R2Score().to(device)(output, val_y)\n                mean_sq_list.append(batch_loss.item())\n                mean_abs_list.append(mean_abs_error.item())\n                r2_list.append(r2_score.item())\n                r_mean_sq_list.append(r_mean_sq_error.item())\n            print(f\"Validating:[{epoch_num+1}/{EPOCHS}] LOSS: {batch_loss.item()}]\")\n        if loss < best_val_loss:\n            best_val_loss = loss\n            counter = 0\n        else: \n            counter += 1\n            if counter >= patience: \n                print(f\"[==] Early Stopping at {loss}\")\n                break\n        \n    sq_mean_loss = np.mean(mean_sq_list)\n    r_sq_mean_loss = np.mean(r_mean_sq_list)\n    abs_mean_loss = np.mean(mean_abs_list)\n    r2_mean_loss = np.mean(r2_list)\n    \n    error = {\"mse_error\" : sq_mean_loss ,\n    \"mae_error\" : abs_mean_loss,\n    \"rmse_error\" : r_sq_mean_loss,\n    \"r2_score\" :  r2_mean_loss}\n    return error,model","metadata":{"execution":{"iopub.status.busy":"2023-01-10T09:48:14.665447Z","iopub.execute_input":"2023-01-10T09:48:14.665784Z","iopub.status.idle":"2023-01-10T09:48:14.684021Z","shell.execute_reply.started":"2023-01-10T09:48:14.665752Z","shell.execute_reply":"2023-01-10T09:48:14.682756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_cv_model(i,model_name,model,optim,losses,output_path=\"./\"):\n\n    ''' This function saves cross validation model in the corresponding directory ( if the path does not exist it creates the path for it'''\n\n\n    if os.path.exists(os.path.join(output_path,f\"{i}_{model_name}_{optim}\")):\n        torch.save(model, os.path.join(output_path,f\"{i}_{model_name}_{optim}/{i}_model.z\"))\n        with open(os.path.join(output_path,f\"{i}_{model_name}_{optim}/losses_{fold}.txt\"),\"w+\") as file:file.write(f\" mse_loss :: {str(losses)}\")\n    else:\n        os.mkdir(os.path.join(output_path,f\"{i}_{model_name}_{optim}\"))\n        torch.save(model, os.path.join(output_path,f\"{i}_{model_name}_{optim}/{i}_model.z\"))\n        with open(os.path.join(output_path,f\"{i}_{model_name}_{optim}/losses_{fold}.txt\"),\"w+\") as file:file.write(f\" mse_loss :: {str(losses)}\")","metadata":{"execution":{"iopub.status.busy":"2023-01-10T09:48:15.168681Z","iopub.execute_input":"2023-01-10T09:48:15.169498Z","iopub.status.idle":"2023-01-10T09:48:15.176984Z","shell.execute_reply.started":"2023-01-10T09:48:15.169454Z","shell.execute_reply":"2023-01-10T09:48:15.176223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = \"MLP\"\noptim_name = best_param[\"optimizer\"]\nfor fold in [x for x in range(K_FOLD)]:\n    dum_model = build_model(IN_FEATURES)\n    print(f\"Training for fold [{fold+1}/{K_FOLD}] started \")\n    error,model = main_train(best_param,dum_model,fold)\n    print(f\"Saving data for fold [{fold+1}/{K_FOLD}]\")\n    save_cv_model(fold,model_name,model,optim_name,error,output_path=\"./\")","metadata":{"execution":{"iopub.status.busy":"2023-01-10T09:48:16.224022Z","iopub.execute_input":"2023-01-10T09:48:16.224400Z","iopub.status.idle":"2023-01-10T09:48:18.815665Z","shell.execute_reply.started":"2023-01-10T09:48:16.224360Z","shell.execute_reply":"2023-01-10T09:48:18.814285Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}